# ============================
# 1. Instalar dependências
# ============================
!pip install pandas numpy matplotlib seaborn scikit-learn lime --quiet

# ============================
# 2. Importar bibliotecas
# ============================
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import lime
import lime.lime_tabular
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix
import os

# ============================
# 3. Carregar dataset (German Credit)
# ============================
url = "https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data"

col_names = [
    "Status", "Duration", "CreditHistory", "Purpose", "CreditAmount",
    "Savings", "EmploymentSince", "InstallmentRate", "PersonalStatusSex",
    "OtherDebtors", "ResidenceSince", "Property", "Age", "OtherInstallment",
    "Housing", "ExistingCredits", "Job", "NumPeopleLiable", "Telephone", "ForeignWorker", "Target"
]

df = pd.read_csv(url, sep=" ", header=None, names=col_names)

# Target: 1=Good, 2=Bad → mapear para 0=Good, 1=Bad
df["Target"] = df["Target"].map({1:0, 2:1})

print("Formato dos dados:", df.shape)
print(df.head())

# ============================
# 4. Separar variáveis
# ============================
X = df.drop("Target", axis=1)
y = df["Target"]

cat_features = X.select_dtypes(include="object").columns.tolist()
num_features = X.select_dtypes(exclude="object").columns.tolist()

# Pré-processamento
preprocessor = ColumnTransformer(
    transformers=[
        ("num", StandardScaler(), num_features),
        ("cat", OneHotEncoder(handle_unknown="ignore"), cat_features)
    ]
)

# ============================
# 5. Modelo
# ============================
model = RandomForestClassifier(
    n_estimators=200,
    random_state=42,
    class_weight="balanced"
)

pipeline = Pipeline(steps=[
    ("preprocessor", preprocessor),
    ("model", model)
])

# ============================
# 6. Treino e avaliação
# ============================
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

pipeline.fit(X_train, y_train)
y_pred = pipeline.predict(X_test)
y_proba = pipeline.predict_proba(X_test)[:,1]

print("\n--- MÉTRICAS ---")
print(classification_report(y_test, y_pred))
print("ROC-AUC:", roc_auc_score(y_test, y_proba))

# Matriz de confusão
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(5,4))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
            xticklabels=["Good","Bad"], yticklabels=["Good","Bad"])
plt.title("Matriz de Confusão")
plt.xlabel("Predito")
plt.ylabel("Real")
plt.tight_layout()
os.makedirs("outputs", exist_ok=True)
plt.savefig("outputs/confusion_matrix.png")
plt.show()

# ============================
# 7. Explicação com LIME
# ============================
# Criar explainer
explainer = lime.lime_tabular.LimeTabularExplainer(
    training_data = pipeline.named_steps["preprocessor"].fit_transform(X_train),
    feature_names = pipeline.named_steps["preprocessor"].get_feature_names_out(),
    class_names = ["Good","Bad"],
    mode="classification"
)

# Escolher um exemplo do teste
i = 5
sample = X_test.iloc[i:i+1]

exp = explainer.explain_instance(
    data_row = pipeline.named_steps["preprocessor"].transform(sample)[0],
    predict_fn = pipeline.predict_proba
)

# Salvar explicação em HTML e PNG
exp.save_to_file("outputs/lime_explanation_sample.html")

fig = exp.as_pyplot_figure()
plt.tight_layout()
plt.savefig("outputs/lime_explanation_sample.png")
plt.show()

print("\nExplicações LIME salvas em 'outputs/' (HTML + PNG).")
