
python lime_credit.py

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import lime
import lime.lime_tabular
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix
import os

# --------------------------
# 1. Carregar Dataset
# --------------------------
url = "https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data"
col_names = [
    "Status", "Duration", "CreditHistory", "Purpose", "CreditAmount",
    "Savings", "EmploymentSince", "InstallmentRate", "PersonalStatusSex",
    "OtherDebtors", "ResidenceSince", "Property", "Age", "OtherInstallment",
    "Housing", "ExistingCredits", "Job", "NumPeopleLiable", "Telephone", "ForeignWorker", "Target"
]

df = pd.read_csv(url, sep=" ", header=None)
df.columns = col_names

# Target: 1=Good, 2=Bad → vamos mapear para 0=Good, 1=Bad
df["Target"] = df["Target"].map({1:0, 2:1})

# --------------------------
# 2. Separar variáveis
# --------------------------
X = df.drop("Target", axis=1)
y = df["Target"]

cat_features = X.select_dtypes(include="object").columns.tolist()
num_features = X.select_dtypes(exclude="object").columns.tolist()

# Pré-processamento
preprocessor = ColumnTransformer(
    transformers=[
        ("num", StandardScaler(), num_features),
        ("cat", OneHotEncoder(handle_unknown="ignore"), cat_features)
    ]
)

# --------------------------
# 3. Modelo
# --------------------------
model = RandomForestClassifier(
    n_estimators=200,
    random_state=42,
    class_weight="balanced"
)

pipeline = Pipeline(steps=[
    ("preprocessor", preprocessor),
    ("model", model)
])

# --------------------------
# 4. Treino e Avaliação
# --------------------------
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

pipeline.fit(X_train, y_train)
y_pred = pipeline.predict(X_test)
y_proba = pipeline.predict_proba(X_test)[:,1]

print("\n--- MÉTRICAS ---")
print(classification_report(y_test, y_pred))
print("ROC-AUC:", roc_auc_score(y_test, y_proba))

cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
            xticklabels=["Good","Bad"], yticklabels=["Good","Bad"])
plt.title("Matriz de Confusão")
plt.xlabel("Predito")
plt.ylabel("Real")
plt.tight_layout()
os.makedirs("outputs", exist_ok=True)
plt.savefig("outputs/confusion_matrix.png")
plt.close()

# --------------------------
# 5. LIME
# --------------------------
# Transformar os dados de treino após pre-processamento
pipeline.fit(X_train, y_train)

explainer = lime.lime_tabular.LimeTabularExplainer(
    training_data = pipeline.named_steps["preprocessor"].fit_transform(X_train),
    feature_names = pipeline.named_steps["preprocessor"].get_feature_names_out(),
    class_names = ["Good","Bad"],
    mode="classification"
)

# Escolher uma amostra do teste
i = 5
sample = X_test.iloc[i:i+1]

exp = explainer.explain_instance(
    data_row = pipeline.named_steps["preprocessor"].transform(sample)[0],
    predict_fn = pipeline.named_steps["model"].predict_proba
)

# Salvar HTML
exp.save_to_file("outputs/lime_explanation_sample.html")

# Salvar PNG (versão estática)
fig = exp.as_pyplot_figure()
plt.tight_layout()
plt.savefig("outputs/lime_explanation_sample.png")
plt.close()

print("\nExplicações LIME salvas em 'outputs/' (HTML + PNG).")

Dependências (requirements.txt)

Crie um arquivo requirements.txt com:

pandas
numpy
matplotlib
seaborn
scikit-learn
lime


E instale com:

pip install -r requirements.txt

Saídas geradas

Quando você rodar, vai encontrar na pasta outputs/:

confusion_matrix.png → matriz de confusão do modelo

lime_explanation_sample.html → explicação interativa da LIME

lime_explanation_sample.png → explicação estática da LIME
